{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fJFEZrfxAdq",
    "outputId": "749caff3-2ab9-46e3-e405-e130267be355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZa7KpjPzax6",
    "outputId": "0a0392da-3609-40cb-b49d-77740418e715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYEeoPg_za0N",
    "outputId": "021b76d3-2b72-45c4-a104-0637f8a7daa5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing all the required libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Loading the dataset into dataframe\n",
    "df = pd.read_csv('/content/restaurant_reviews_az.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Al9t5p3Vpu_k",
    "outputId": "3ffaf0f3-45df-4aeb-a108-af63a549ddc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
      "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
      "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
      "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
      "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      3       1      1     0   \n",
      "1      5       1      1     1   \n",
      "2      5       1      0     0   \n",
      "3      5       0      0     0   \n",
      "4      4       1      0     0   \n",
      "\n",
      "                                                text                 date  \n",
      "0  OK, the hype about having Hatch chili in your ...  2020-01-27 22:59:06  \n",
      "1  Pandemic pit stop to have an ice cream.... onl...  2020-04-19 05:33:16  \n",
      "2  I was lucky enough to go to the soft opening a...  2020-02-29 19:43:44  \n",
      "3  I've gone to claim Jumpers all over the US and...  2020-03-14 21:47:07  \n",
      "4  If you haven't been  to Maynard's kitchen, it'...  2020-01-17 20:32:57  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48147 entries, 0 to 48146\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   review_id    48147 non-null  object\n",
      " 1   user_id      48147 non-null  object\n",
      " 2   business_id  48147 non-null  object\n",
      " 3   stars        48147 non-null  int64 \n",
      " 4   useful       48147 non-null  int64 \n",
      " 5   funny        48147 non-null  int64 \n",
      " 6   cool         48147 non-null  int64 \n",
      " 7   text         48147 non-null  object\n",
      " 8   date         48147 non-null  object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 3.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing the first 5 rows of the dataframe and its summary info\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "tgr9jY42za2V"
   },
   "outputs": [],
   "source": [
    "# Selecting 1 star reviews and 5 star reviews\n",
    "one_star_reviews = df[df['stars'] == 1]['text'].values\n",
    "five_star_reviews = df[df['stars'] == 5]['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "wD5ACBvrBwhd"
   },
   "outputs": [],
   "source": [
    "# Applying text processing techniques to return list of lemmatized words without stopwords\n",
    "def text_processing(review):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = word_tokenize(review)\n",
    "    filtered_review = [lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words]\n",
    "    return filtered_review\n",
    "\n",
    "# Applying text processing on 1 star reviews and 5 star reviews\n",
    "one_star_reviews_processed = [text_processing(review) for review in one_star_reviews]\n",
    "five_star_reviews_processed = [text_processing(review) for review in five_star_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "piQt5dv0C0rI",
    "outputId": "99b46d75-504b-4e7d-82c0-68f5b9d6aa60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 6134), ('order', 5318), ('time', 4294), ('place', 3229), ('service', 2838), ('minute', 2262), ('customer', 2101), ('restaurant', 1869), ('manager', 1509), ('people', 1392), ('hour', 1222), ('location', 1167), ('experience', 1111), ('way', 1064), ('staff', 988), ('employee', 980), ('pizza', 930), ('meal', 861), ('chicken', 853), ('table', 852)]\n",
      "[('food', 14814), ('place', 10598), ('time', 7013), ('service', 6585), ('Tucson', 4894), ('restaurant', 4141), ('order', 3933), ('staff', 3707), ('menu', 2672), ('Great', 2456), ('flavor', 2373), ('pizza', 2220), ('experience', 2211), ('meal', 2029), ('spot', 1932), ('chicken', 1931), ('sauce', 1912), ('taco', 1849), ('day', 1792), ('everything', 1775)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Function to get nouns\n",
    "def get_nouns(tagged_words):\n",
    "    return [word for word, pos in tagged_words if pos.startswith('N')]\n",
    "\n",
    "# Retrieving nouns for 1 star reviews and 5 star reviews\n",
    "one_star_nouns = [get_nouns(pos_tag(review)) for review in one_star_reviews_processed]\n",
    "five_star_nouns = [get_nouns(pos_tag(review)) for review in five_star_reviews_processed]\n",
    "\n",
    "# Converting nested lists into one dimensional lists\n",
    "one_star_nouns_flat = [word for sublist in one_star_nouns for word in sublist]\n",
    "five_star_nouns_flat = [word for sublist in five_star_nouns for word in sublist]\n",
    "\n",
    "# Geting the top 20 frequently used nouns\n",
    "top_20_one_star_nouns = Counter(one_star_nouns_flat).most_common(20)\n",
    "top_20_five_star_nouns = Counter(five_star_nouns_flat).most_common(20)\n",
    "\n",
    "print(top_20_one_star_nouns)\n",
    "print(top_20_five_star_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8W3P_cY7ulYX",
    "outputId": "3b08b7a0-730f-4d6e-9084-efb185bdf86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 2252), ('good', 1659), ('bad', 1135), ('last', 838), ('table', 833), ('great', 672), ('first', 659), ('wrong', 629), ('sure', 576), ('worst', 551), ('new', 550), ('many', 530), ('much', 508), ('terrible', 504), ('small', 498), ('next', 474), ('old', 470), ('horrible', 464), ('disappointed', 463), ('little', 444)]\n",
      "[('great', 9366), ('good', 8623), ('delicious', 6354), ('best', 3851), ('fresh', 2840), ('nice', 2420), ('favorite', 2240), ('u', 2190), ('friendly', 1943), ('little', 1854), ('hot', 1572), ('first', 1572), ('new', 1515), ('happy', 1393), ('many', 1374), ('sure', 1330), ('next', 1236), ('special', 1196), ('perfect', 1150), ('super', 1142)]\n"
     ]
    }
   ],
   "source": [
    "# Function to get adjectives\n",
    "def get_adjectives(tagged_words):\n",
    "    return [word for word, pos in tagged_words if pos.startswith('J')]\n",
    "\n",
    "# Getting adjectives for 1 star reviews and 5 star reviews\n",
    "one_star_adjectives = [get_adjectives(pos_tag(review)) for review in one_star_reviews_processed]\n",
    "five_star_adjectives = [get_adjectives(pos_tag(review)) for review in five_star_reviews_processed]\n",
    "\n",
    "# Converting nested lists into one dimensional lists\n",
    "one_star_adjectives_flat = [word for sublist in one_star_adjectives for word in sublist]\n",
    "five_star_adjectives_flat = [word for sublist in five_star_adjectives for word in sublist]\n",
    "\n",
    "# Getting the top 20 frequently used adjectives\n",
    "top_20_one_star_adjectives = Counter(one_star_adjectives_flat).most_common(20)\n",
    "top_20_five_star_adjectives = Counter(five_star_adjectives_flat).most_common(20)\n",
    "\n",
    "print(top_20_one_star_adjectives)\n",
    "print(top_20_five_star_adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jehATRzxEshX",
    "outputId": "8eb2728f-2961-45fa-b580-405a6dcd9255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('get', 2422), ('go', 2415), ('ordered', 2390), ('said', 2362), ('got', 2201), ('asked', 1899), ('told', 1712), ('came', 1580), ('went', 1454), (\"'ve\", 1425), (\"'m\", 1335), ('going', 1302), ('know', 1192), ('say', 1141), ('come', 1137), ('took', 1031), ('make', 985), ('take', 980), ('waiting', 913), ('made', 902)]\n",
      "[(\"'ve\", 4495), ('go', 4082), ('ordered', 3476), ('got', 3448), ('get', 3128), ('love', 2870), (\"'m\", 2581), ('made', 2555), ('recommend', 2404), (\"'s\", 2367), ('come', 2299), ('amazing', 2242), ('make', 1986), (\"'re\", 1984), ('came', 1958), ('tried', 1601), ('try', 1566), ('went', 1499), ('take', 1469), ('going', 1419)]\n"
     ]
    }
   ],
   "source": [
    "# Function to get verbs\n",
    "def get_verbs(tagged_words):\n",
    "    return [word for word, pos in tagged_words if pos.startswith('V')]\n",
    "\n",
    "# Getting verbs for 1 star reviews and 5 star reviews\n",
    "one_star_verbs = [get_verbs(pos_tag(review)) for review in one_star_reviews_processed]\n",
    "five_star_verbs = [get_verbs(pos_tag(review)) for review in five_star_reviews_processed]\n",
    "\n",
    "# Converting nested lists into one dimensional lists\n",
    "one_star_verbs_flat = [word for sublist in one_star_verbs for word in sublist]\n",
    "five_star_verbs_flat = [word for sublist in five_star_verbs for word in sublist]\n",
    "\n",
    "# Getting the top 20 frequently used verbs\n",
    "top_20_one_star_verbs = Counter(one_star_verbs_flat).most_common(20)\n",
    "top_20_five_star_verbs = Counter(five_star_verbs_flat).most_common(20)\n",
    "\n",
    "print(top_20_one_star_verbs)\n",
    "print(top_20_five_star_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tWUWbAIC0vs",
    "outputId": "32b8c60d-be64-4db5-90d2-e7ecc7d2ed6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PERSON', 9737), ('ORGANIZATION', 4082), ('GPE', 3300), ('GSP', 23), ('LOCATION', 17), ('FACILITY', 13)]\n",
      "[('PERSON', 34484), ('GPE', 15141), ('ORGANIZATION', 7855), ('LOCATION', 173), ('GSP', 107), ('FACILITY', 40)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "# Function to get named entities\n",
    "def get_named_entities(words):\n",
    "    tagged_words = pos_tag(words)\n",
    "    named_entities = ne_chunk(tagged_words)\n",
    "    return [chunk.label() for chunk in named_entities if hasattr(chunk, 'label')]\n",
    "\n",
    "# Get named entities for 1 star reviews and 5 star reviews\n",
    "one_star_entities = [get_named_entities(review) for review in one_star_reviews_processed]\n",
    "five_star_entities = [get_named_entities(review) for review in five_star_reviews_processed]\n",
    "\n",
    "# Converting nested lists into one dimensional lists\n",
    "one_star_entities_flat = [entity for sublist in one_star_entities for entity in sublist]\n",
    "five_star_entities_flat = [entity for sublist in five_star_entities for entity in sublist]\n",
    "\n",
    "# Getting the top 20 frequently used named entities\n",
    "top_20_one_star_entities = Counter(one_star_entities_flat).most_common(20)\n",
    "top_20_five_star_entities = Counter(five_star_entities_flat).most_common(20)\n",
    "\n",
    "print(top_20_one_star_entities)\n",
    "print(top_20_five_star_entities)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
